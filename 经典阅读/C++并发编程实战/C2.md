# 3. 同步并发操作

C++提供了==条件变量==和==期望==来进行线程同步。

## 3.1等待一个事件或其他条件

 :one:标准C++库提供了两个条件变量的实现：	`std::condition_variable`和`std::condition_variable_any`。这两个实现都包含在`<condition_variable>`头文件的声明中。两者都需要与一个**互斥量**一起才能工作（互斥量是为了同步）；前者仅限于与`std::mutex`一起工作，而后者可以和**任何满足最低标准的互斥量**一 起工作，从而加上了`_any`的后缀。

因为`std::condition_variable_any`更加通用，这就可能从体积、性能，以及系统资源的使用方面产生额外的开销，所以`std::condition_variable`一般作为首选的类型，当对灵活性有硬性要求时，我们才会去考虑`std::condition_variable_any`。

怎么使用呢？

```c++
 std::mutex mut;
std::queue<data_chunk> data_queue; // 1
std::condition_variable data_cond;
void data_preparation_thread()
{
while(more_data_to_prepare())
    {
        data_chunk const data = prepare_data();
        std::lock_guard<std::mutex> lk(mut);
        data_queue.push(data); // 2
        data_cond.notify_one(); // 3
    }
}

void data_processing_thread()
{
    while(true)
    {
        std::unique_lock<std::mutex> lk(mut); // 4
        data_cond.wait(
        	lk,[]{return !data_queue.empty();}); // 5
        
        data_chunk data = data_queue.front();
        data_queue.pop();
        lk.unlock(); // 6
        process(data);
        if(is_last_chunk(data))
        	break;
    }
}
```

具体分析可以见书P 66，或者自己分析。需要注意：`std::condition_variable`的`notify_one()`成员函数，对等待的线程（如果有等待线程）进行通知。

:two:使用条件变量构建**线程安全队列**：

```c++
#include<condition_variable>
#include<thread>
#include<mutex>
#include<queue>
#include<memory>

template<typename T>
class threadsafe_queue {
private:
	mutable std::mutex mut; //互斥量必须是可变的

	std::queue<T>data_queue;
	std::condition_variable data_cond;
public:
	threadsafe_queue() {}
	threadsafe_queue(threadsafe_queue const& other) {
		std::lock_guard<std::mutex> lk(other.mut);
		data_queue = other.data_queue;
	}

	void push(T new_value) {
		std::lock_guard<std::mutex> lk(mut);
		data_queue.push(new_value);
		data_cond.notify_one();
	}

	void wait_and_pop(T& value) {
		std::unique_lock<std::mutex> lk(mut);
		data_cond.wait(lk, [this] {return !data_queue.empty();});
		value = data_queue.front();
		data_queue.pop();
	}

	std::shared_ptr<T> wait_and_pop() {
		std::unique_lock<std::mutex> lk(mut);
		data_cond.wait(lk, [this] {return !data_queue.empty();});
		std::shared_ptr<T> res(std::make_shared<T>(data_queue.front()));
		data_queue.pop();
		return res;
	}

	bool try_pop(T& value) {
		std::lock_guard<std::mutex> lk(mut);
		if (data_queue.empty())
			return false;
		value = data_queue.front();
		data_queue.pop();
		return true;
	}

	bool empty() {
		std::lock_guard<std::mutex> lk(mut);
		return data_queue.empty();
	}
};
```



## 3.2 使用期望等待一次性事件

:one:`future`线程会周期性的等待或检查，事件是否触发；在检查期间也会执行其他任务。直到对应的任务触发，而后等待期望的状态会变为**“就绪”(ready)**。一个“期望”可能是数据相关的，也可能不是。当事件发生时（并且期望状态为就绪），**这个“期望”就不能被重置**。

在C++标准库中，有两种“期望”，使用两种类型模板实现，声明在头文件`<future>`中：==唯一期望==( `std::future<>` )和==共享期望==( `std::shared_future<> `)。这是仿照 `std::unique_ptr`和 `std::shared_ptr` 。 

后者的实现中，所有实例会在同时变为**就绪状态**，并且他们可以访问与事件相关的**任何数据**。这些**关联的数据**就是它们成为模板的原因。在与数据无关的地方，可以使用 `std::future `与 `std::shared_future `的特化模板。

`std::thread`执行的任务不能有返回值，**这个问题将在使用“期望”后解决**；

:two:解决方法是使用`std::async`启动一个==异步任务==，其返回一个`std::feature`对象（持有函数返回值）。我们需要时，只需要在上面调用`get()`。一个简单的例子：

```c++
#include <future>
#include <iostream>
int find_the_answer_to_ltuae();
void do_other_stuff();
int main()
{
    std::future<int> the_answer = std::async(find_the_answer_to_ltuae);
    do_other_stuff();
    std::cout<<"The answer is "<<the_answer.get()<<std::endl;
}

```

与 `std::thread` 做的方式一样， `std::async`允许通过添加额外的调用参数，向函数传递额外的参数。当第一个参数是一个指向成员函数的指针，第二个参数提供有这个函数成员类的具体对象（不是直接的，就是通过指针，还可以包装在 `std::ref `中），剩余的参数可作为**成员函数的参数**传入。否则，第二个和随后的参数将作为函数的参数。

```c++
#include <string>
#include <future>
struct X
{
    void foo(int,std::string const&);
    std::string bar(std::string const&);
};

X x;
auto f1 = std::async(&X::foo,&x,42,"hello"); // 调用p->foo(42, "hello")，p是指向x的指针
auto f2 = std::async(&X::bar,x,"goodbye"); // 调用tmpx.bar("goodbye")， tmpx是x的拷贝副本

struct Y
{
	double operator()(double);
};
Y y;
auto f3 = std::async(Y(),3.141); // 调用tmpy(3.141)，tmpy通过Y的移动构造函数得到
auto f4 = std::async(std::ref(y),2.718); // 调用y(2.718)

X baz(X&);
std::async(baz, std::ref(x)); // 调用baz(x)

class move_only
{
public:
    move_only();
    move_only(move_only&&)
    move_only(move_only const&) = delete;
    move_only& operator=(move_only&&);
    move_only& operator=(move_only const&) = delete;
    void operator()();
};
auto f5 = std::async(move_only()); // 调用tmp()，tmp是通过std::move(move_only())构造得到
```

:three:可以在函数调用之前使用一个额外参数来指定究竟使用什么启动方式，这个参数为`std::launch`类型：

- `std::launch::deferred`，表面该函数调用会延迟，直到在future上调用`wait()`或`get()`。
- `std::launch::async`表明该函数必须允许在它自己的线程上。
- 1|2：表明可以由具体实现来选择。这是默认的。

在本章的后面和第8章中，你将会再次看到这段程序，使用 `std::async `会让**分割算法到各个任务中变的容易**，这样程序就能并发的执行了。

### 任务与期望

`std::packaged_task<>`对一个函数或可调用对象，绑定一个期望。当`std::packaged_task<>`对象被调用，它就会调用**相关函数或可调用对象**，将期望状态置为**就绪**，返回值作为**关联数据**存储。

其**模板参数**为**函数签名**，例如`int(string&, double*)`。当然也无需严格匹配，只要可以进行转换。

```c#
#include <deque>
#include <mutex>
#include <future>
#include <thread>
#include <utility>
std::mutex m;
std::deque<std::packaged_task<void()> > tasks;
bool gui_shutdown_message_received();
void get_and_process_gui_message();

void gui_thread() // 1
{
    while(!gui_shutdown_message_received()) // 2
    {
        get_and_process_gui_message(); // 3
        std::packaged_task<void()> task;
        {
            std::lock_guard<std::mutex> lk(m);
            if(tasks.empty()) // 4
            	continue;
            task = std::move(tasks.front()); // 5
            tasks.pop_front();
		}
	task(); // 6
	}
}

std::thread gui_bg_thread(gui_thread);

template<typename Func>
std::future<void> post_task_for_gui_thread(Func f)
{
    std::packaged_task<void()> task(f); // 7
    std::future<void> res = task.get_future(); // 8
    std::lock_guard<std::mutex> lk(m); // 9
    tasks.push_back(std::move(task)); // 10
    return res;
}

```

### 使用`std::promises`

`std::promise` 提供设定值的方式（类型为T），这个类型会和`std::future`对象相关联。一对 `std::promise/std::future`提供一个可行的机制；等待线程可以阻塞期望，同时，提供数据的线程可以使用“promise”来对相关值进行设置，将“**期望**”的状态置为“**就绪**”。

可以通过`get_future()`成员函数来获取与一个给定的 `std::promise` 相关的 `std::future` 对象。当“promise”的值设置完毕（使用`set_value()`成员函数），对应“**期望**”的状态变为“**就绪**”，并且可用于检索**已存储的值**。当你在设置值之前销毁 `std::promise` ，将会存储一个==异常==。

```c++
#include <future>
void process_connections(connection_set& connections)
{
    while(!done(connections)) // 1
    {
        for(connection_iterator // 2
            connection = connections.begin(), end = connections.end();
            connection != end;
            ++connection)
            {
                if(connection->has_incoming_data()) // 3
                {
                    data_packet data = connection->incoming();
                    std::promise<payload_type>& p = connection->get_promise(data.id); // 4
                    p.set_value(data.payload);
                }
                if(connection->has_outgoing_data()) // 5
                {
                    outgoing_packet data =
                    connection->top_of_outgoing_queue();
                    connection->send(data.payload);
                    data.promise.set_value(true); // 6
                }
        	}
    }
}
```

### 考虑异常

之前的三种方法都没有考虑异常。但实际上，如果线程上的函数引发异常，该异常会存储在`future`中，代替所存储的值，变为就绪，并且对`get()`的调用会重新引发**所存储的异常**。

这同样发生在将函数**封装**入`std::packaged_task`的时候，以及`std::promise`。当你希望存入的是一个异常而非一个数值时，你就需要调用`set_exception()`成员函数，而非`set_value()`。这通常是用在一个catch块中：

```c#
extern std::promise<double> some_promise;
try
{
	some_promise.set_value(calculate_value());
}
catch(...)
{
	some_promise.set_exception(std::current_exception());
}
```

这里使用了 `std::current_exception() `来检索抛出的异常；可用 `std::copy_exception() `作为一个替换方案，`std::copy_exception() `会直接存储一个新的异常而不抛出：

```c++
some_promise.set_exception(std::copy_exception(std::logic_error("foo ")));
```

当异常类型是已知的，这就比使用`try/catch`块更加清晰，就应该优先被使用；不是因为代码实现简单，而是它给编译器提供了**极大的代码优化空间**。

直到现在，所有例子都在用 `std::future `。不过， `std::future` 也有局限性，很多线程在等待的时候，只有一个线程能获取等待结果。当多个线程需要等待相同的事件的结果，你就需要使用 `std::shared_future` 来替代 `std::future` 了。



### 多个线程的等待

在每一个 `std::shared_future`的独立对象上，成员函数调用返回的结果还是不同步的，所以为 了在多个线程访问一个独立对象时，避免数据竞争，必须使用锁来对访问进行保护。优先使用的办法：让每个线程都拥有自己对应的拷贝对象。这样，当每个线程都通过自己拥有的 `std::shared_future `对象获取结果，那么多个线程访问**共享同步结果**就是安全的。

![image-20210608195937649](C2.assets\image-20210608195937649.png)

`std::shared_future `的实例同步 `std::future `实例的状态。当 `std::future `对象没有与其他对 象共享同步状态所有权，那么所有权必须使用 `std::move` 将所有权传递到 `std::shared_future` ，其默认构造函数如下：

```c++
std::promise<int> p;
std::future<int> f(p.get_future());
assert(f.valid()); // 1 "期望" f 是合法的
std::shared_future<int> sf(std::move(f));
assert(!f.valid()); // 2 "期望" f 现在是不合法的
assert(sf.valid()); // 3 sf 现在是合法的
```

`std::future` 有一个`share()`成员函数， 可用来创建新的`std::shared_future `，并且可以直接转移“**期望**”的所有权。这样也就能保存很多类型，并且使得代码易于修改：

```c++
std::promise< std::map< SomeIndexType, SomeDataType, SomeComparator,
SomeAllocator>::iterator> p;
auto sf = p.get_future().share();
```



## 3.3 有时间限制的等待

:one:之前介绍过的所有**阻塞调用**，将会阻塞一段不确定的时间，将线程挂起直到等待的事件发生。在很多情况下，这样的方式很不错，但是在其他一些情况下，就需要限制一下线程等待的时间。

等待时间的设置有2种方式：

- 时延方式，等待一段指定时间
- 绝对时间，等待到固定的时间点。

处理**持续时间**的变量以“`for`”作为后缀，处理**绝对时间**的变量 以`until`作为后缀。而每个又有两个重载版本，其中一个重载只是等待信号触发，或时间超期；亦或是一个虚假的唤醒，并且唤醒时，会检查**锁**提供的谓词，并且只有在检查为`true`时才会返回（这时条件变量的条件达成），或直接超时。

### 时钟

:one:对于C++标准库来说，时钟就是信息源。时钟是一个类，提供了四种不同的信息：现在时间、时间类型、时钟节拍、**通过时钟节拍的速率，判断时钟是否稳定**。

**时钟的当前时间**可以通过调用静态成员函数`now()`从时钟类中获取；例如， `std::chrono::system_clock::now()` 返回系统时钟的当前时间。

**时钟节拍**被指定为`1/x`秒，这是由时间周期所决定——一个时钟一 秒有25个节拍，因此一个周期为` std::ratio<1, 25> `，当一个时钟的时钟节拍每2.5秒一次， 周期就可以表示为 `std::ratio<5, 2> `。

当**时钟节拍**均匀分布，并且不可调整，这种时钟就称为==稳定时钟==。当` is_steady`静态数据成员为`true`时，表明这个时钟就是稳定的。通常情况下， `std::chrono::system_clock` 是不稳定的，因为是可调的。

稳定闹钟对于超时的计算很重要，所 以C++标准库提供一个稳定时钟 `std::chrono::steady_clock `。`std::chrono::high_resolution_clock` 可能是标准库中提供的具有**最小节拍周期**的时钟。

:two:==时延==是时间部分最简单的；`std::chrono::duration<> `函数模板能够对**时延**进行处理（线程库使用到的所有C++时间处理工具，都在 `std::chrono` 命名空间内)。第一个模板参数是一个**类型表示**（比如，int，long或double），第二个模板参数是制定部分，表示每一个单元所用秒数。例如，当几分钟的时间要存在`short`类型中时，可以写成 `std::chrono::duration<short, std::radio<60, 1>>` ，因为**60秒**是才是**1分钟**，所以第二个参数写成 `std::ratio<60, 1> `。另一 方面，当需要将毫秒级计数存在`double`类型中时，可以写成 `std::chrono::duration<short, std::radio<1000, 1>>` ，因为1秒等于1000毫秒。

标准库在` std::chrono `命名空间内，为**延时变量**提供一系列**预定义类型**：nanoseconds[纳秒] , microseconds[微秒] , milliseconds[毫秒] , seconds[秒] , minutes[分]和hours[时]。==显示转换==可以由 `std::chrono::duration_cast<>` 来完成。

```c#
std::chrono::milliseconds ms(54802);
std::chrono::seconds s = std::chrono::duration_cast<std::chrono::seconds>(ms);
```

这里的结果就是截断的，而不是进行了舍入，所以`s`最后的值将为`54`。

**基于时延的等待**可由 `std::chrono::duration<> `来完成。例如，你等待一个“期望”状态变为就绪 ，最多35毫秒：

```c++
std::future<int> f = std::async(some_task);
if(f.wait_for(std::chrono::milliseconds(35)) == std::future_status::ready)
	do_something_with(f.get());
```

基**于时延的等待**是使用内部库提供的**稳定时钟**，来进行计时的。难以预料的系统调度和不同操作系统的**时钟精度**都意味着：在线程中，从调用到返回的实际时间可能要比`35`毫秒长。

:three:==时间点==可以用 `std::chrono::time_point<> `的类型模板实例来表示，实例的第一个参数用来指定所**要使用的时钟**，第二个函数参数用来表示**时间的计量单位**（特化的 `std::chrono::duration<> `)。

**时间戳**是时钟的一个基本属性，但是不可以直接查询。当两个时钟共享一个时间戳时，其中一个`time_point`类型可以与另一个时钟类型中的`time_point`相关联，可以通过对指定time_point类型使用`time_since_epoch()`来获取时间戳。这个成员函数会返回一个**时延值**，这个时延值是**指定时间点**到时钟的时间戳 。

可以通过 `std::chrono::time_point<> `实例来加/减时延，来获得一个**新的时间点**。

可以减去一个时间点（二者需要共享同一个时钟），结果是两个时间点的时间差：

```c++
auto start = std::chrono::high_resolution_clock::now();
do_something();
auto stop = std::chrono::high_resolution_clock::now();
std::cout << ”do_something() took “
<< std::chrono::duration<double, std::chrono::seconds>(stop - start).count()
<< ” seconds”<< std::endl;
```

```c++
#include <condition_variable>
#include <mutex>
#include <chrono>
std::condition_variable cv;
bool done;
std::mutex m;
bool wait_loop()
{
    auto const timeout = std::chrono::steady_clock::now() + std::chrono::milliseconds(500);
    std::unique_lock<std::mutex> lk(m);
    while(!done)
    {
        if(cv.wait_until(lk, timeout) == std::cv_status::timeout)
            break;
    }
    return done;
}
```

### 具有超时功能的函数

使用超时的**最简单方式**就是，对一个**特定线程**添加一个**延迟处理**；当这个线程无所事事时， 就不会**占用**可供其他线程处理的**时间**。

:one:使用==睡眠==，​两个处理函数分别是`std::this_thread::sleep_for()`和 `std::this_thread::sleep_until()` 。

超时可以配合**条件变量**和`future`一起使 用。**超时**甚至可以在尝试获取一个**互斥锁**时使用。 `std::mutex`和`std::recursive_mutex`都不支持超时锁，但是 `std::timed_mutex` 和 `std::recursive_timed_mutex `支持。这两种类型也有`try_lock_for()`和` try_lock_until()`成员函数。

C++标准库中**支持超时的函数**：参数列表为“延时”必须是 `std::duration<> `的实例，而列出为“时间点”必须是 `std::time_point<> `的实例。

![image-20210609193247935](C2.assets\image-20210609193247935-1623238370072.png)



## 3.4 使用同步操作简化代码

**同步工具的使用**在本章称为==构建块==，你可以只关注那些需要同步的操作，而非具体使用的机制。当需要为程序设计并发时，这是一种**简化代码的方式**，提供更多的**函数化方法**。比起在多个线程间直接共享数据，每个任务拥有自己的数据应该会更好，并且结果可以对其他线程进行**广播**，这就需要使用**“期 望”**来完成了。

### 使用期望的函数化编程

术语==“函数化编程”（functional programming ( FP )）==引用于一种编程方式，这种方式中的函数结果只依赖于传入函数的参数，**不依赖外部状态**。

> 当共享数据没有被修改，那么就不存在条件竞争，并且没有必要使用互斥量去保护共享数据。

C++是一个多范型的语言，其也可以写出FP类型的程序，特别在支持**lambda表达式**之后。**“期望”**作为拼图的最后一块，它使得==函数化编程模式并发化==（`FP-style concurrency`）在C++中成为可能；**一个“期望”对象可以在线程间互相传递，并允许其中一个计算结果依赖于另外一个的结果，而非对共享数据的显式访问**。

为了描述在**函数化(PF)并发**中使用**“期望”**，让我们来看看一个简单的实现——**快速排序算法**。

```c++
template<typename T>
std::list<T> sequential_quick_sort(std::list<T> input)
{
    if(input.empty())
    {
    	return input;
    }
    
	std::list<T> result;
    //使用splice()将输入的首个元素(中间值)放入结果列表中。
    result.splice(result.begin(), input, input.begin()); // 1
    T const& pivot = *result.begin(); // 2
    //std::partition() 对列表进行重置，并返回一个指向首元素(不小于“中间”值)的迭代器。
    auto divide_point = std::partition(input.begin(), input.end(),
    						[&](T const& t){ return t < pivot; }); // 3
    
    std::list<T> lower_part;
    lower_part.splice(lower_part.end(), input, input.begin(), divide_point); // 4
    
    //递归调用
    auto new_lower(sequential_quick_sort(std::move(lower_part))); // 5
    auto new_higher(sequential_quick_sort(std::move(input))); // 6
    
    //再次使用splice()，将result中的结果以正确的顺序进行拼接
    result.splice(result.end(), new_higher); // 7
    result.splice(result.begin(), new_lower); // 8
    return result;
}
```

快速排序——FP模式线程强化版：

```c++
template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input)
{
if(input.empty())
{
return input;
}
std::list<T> result;
result.splice(result.begin(),input,input.begin());
T const& pivot=*result.begin();
auto divide_point=std::partition(input.begin(),input.end(),
[&](T const& t){return t<pivot;});
std::list<T> lower_part;
lower_part.splice(lower_part.end(),input,input.begin(),
divide_point);
std::future<std::list<T> > new_lower( // 1
std::async(&parallel_quick_sort<T>,std::move(lower_part)));
auto new_higher(
parallel_quick_sort(std::move(input))); // 2
result.splice(result.end(),new_higher); // 3
result.splice(result.begin(),new_lower.get()); // 4
return result;
}
```

