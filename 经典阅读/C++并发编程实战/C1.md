# 1. 管理线程

## 1.1 基本线程管理

线程是通过构造`std::thread`对象来开始的，该对象指定了线程上要运行的任务。如同大多数 C++标准库一样，`std::thread` 可以用**可调用（callable）类型**构造，将带有**函数调用符类型的实例**传入 std::thread 类中，替换默认的构造函数。

```c++
class background_task
{
public:
    void operator()() const
    {
        do_something();
        do_something_else();
    }
};
background_task f;
std::thread my_thread(f);

```

或者使用`lambda`表达式：

```c++
std::thread my_thread([]{
    do_something();
    do_something_else();
});
```

启动了线程，你需要明确是要等**待线程结束**（加入），还是让其**自主运行**（分离）。如果 std::thread 对象销毁之前还没有做出决定，程序就会终止 ( **std::thread 的析构函数**会调用 **std::terminate()** )。因此，即便是有异常存在，也需要确保线程能够正确的加入(`joined`)或分离(`detached`)。

如果不等待线程，就必须保证线程结束之前，**可访问数据的有效性**。这种情况很可能发生在线程还没结束，函数已经退出的时候，这时线程函数还持有**函数局部变量的指针或引用**。

```c++
//清单2.1
struct func
{
    int& i;
    func(int& i_) : i(i_) {}
    void operator() ()
    {
        for (unsigned j = 0 ; j<1000000 ; ++j)
        {
        	do_something(i); // 1. 潜在访问隐患：悬空引用
        }
    }
};

void oops()
{
    int some_local_state = 0;
    func my_func(some_local_state);
    std::thread my_thread(my_func);
    my_thread.detach(); // 2. 不等待线程结束
} // 3. 新线程可能还在运行

```

> 上面会调用已经释放的变量`i`

### 等待线程完成

如果需要**等待线程**，相关的 **std::tread 实例**需要使用``join()``。清单2.1中， 将 `my_thread.detach() `替换为 `my_thread.join() `，就可以确保局部变量在线程完成后，才被销毁。

`join()`是简单粗暴的等待线程完成或不等待。==只能对一个线程使用一次join()；==一旦已经使用过 join()， **std::thread 对象**就不能再次加入了，当对其使用``joinable()``时，将返回否（false）。

如果打算**等待对应线程**，则需要细心挑选**调用join()的位置**。当在线程运行之后产生异常，在join()调用之前抛出，就意味着很这次调用会被跳过。 避免应用被抛出的异常所终止，就需要作出一个决定。通常，当==倾向于在无异常的情况下使用join()时，需要在异常处理过程中调用join()==，从而避免生命周期的问题。下面的程序清单是 一个例子。

```c++
struct func; // 定义在清单2.1中
void f()
{
    int some_local_state =0;
    func my_func(some_local_state);
    std::thread t(my_func);
    try
    {
    	do_something_in_current_thread();
    }
    catch(...)
    {
        t.join(); // 1
        throw;
    }
    t.join(); // 2
}
```

一种更好方式是使用“**资源获取即初始化方式**”(==RAII==，Resource Acquisition Is Initialization)，并且提供一个类，在**析构函数**中使用join()，如同下面清单中的代码。看它如何简化``f()``函数。

``` c
//清单2.4
class thread_guard
{
    std::thread& t;
    
    public:
    explicit thread_guard(std::thread& t_):
    t(t_){}
    
    ~thread_guard()
    {
        if(t.joinable()) // 1
        {
        	t.join(); // 2
        }
    }
    
    thread_guard(thread_guard const&) = delete; // 3
    thread_guard& operator=(thread_guard const&) = delete;
};
struct func; // 定义在清单2.1中
void f()
{
    int some_local_state = 0;
    func my_func(some_local_state);
    std::thread t(my_func);
    thread_guard g(t);
    do_something_in_current_thread();
} // 4

```

### 后台运行线程

使用``detach()``会让线程在后台运行，这就意味着主线程不能与之产生直接交互。也就是说，不会等待这个线程结束；如果线程分离，那么就不可能有 **std::thread 对象**能引用它。通常称**分离线程**为**守护线程**（daemon threads），应用场景是两个极端：

+ 长时间运行

+ "发后即忘"(fire and forget)的任务

  

## 1.2 传递参数给线程函数

向`std::thread`构造函数中的**可调用对象**传递一个参数很简单。需要注意的是，参数会==拷贝==到线程的**独立内存**中，即使参数是**引用**的形式。

```c++
void f(int, std::string const&);
std::thread t(f, 3, "hello");
```

> 这里使用的是字符串的字面值，也就是`char const*`，所以实际上会进行到`string`的转换。

那么如果我们使用**分离形式**，那么可能这个转换还没完成，主程序就结束了，那么就会导致**未定义行为**：

```c++
void f(int i,std::string const& s);
void not_oops(int some_param)
{
    char buffer[1024];
    sprintf(buffer,"%i",some_param);
    std::thread t(f,3,buffer); // 使用std::string，避免悬垂指针
    t.detach();
}
```

:two:那我们想要一个**引用**时（例如，更新数据），怎么办？使用`std::ref`来包装参数：

```c++
std::thread t(update_data_for_widget, w, std::ref(data));
```

:three:如果想要启动一个==成员函数==，则第一个参数是**函数指针**，第二个参数是**对象指针**，第三个开始才是**参数**：

```c++
class X
{
    public:
    void do_lengthy_work();
};
X my_x;
std::thread t(&X::do_lengthy_work, &my_x); // 1
```

:four:另一个有趣场景是：参数只能移动（下面的`std::unique_ptr`），不能复制：

```c++
void process_big_object(std::unique_ptr<big_object>);

....
std::unique_ptr<big_object> p(new big_object);
p->prepare_data(42);
std::thread t(process_big_object, std::move(p));
```

`std::thread`==是可移动的，但不是可复制的==。



## 1.3 转移线程所有权

:one:**转移线程的所有权**是`std::thread`支持移动的由来。

```c++
void some_function();
void some_other_function();
std::thread t1(some_function); // 1
std::thread t2 = std::move(t1); // 2
t1 = std::thread(some_other_function); // 3
std::thread t3; // 4
t3 = std::move(t2); // 5
t1 = std::move(t3); // 6 赋值操作将使程序崩溃
```

在**3**处，我们需要注意：对于一个临时的线程对象，不需要显示调用`std::move`来显示移动所有权（或者说这个时候，这是个右值，不需要强制类型转换）。

最后会崩溃是因为：`t1`已经有了一个关联的线程，会调用` std::terminate()` 终止程序，以和析构函数保持一致。

> 我们必须在析构前，显示等待线程**完成**或**分离**，这同样适用于**赋值**。

:two:从**函数**中返回**线程所有权**：

```c++
std::thread f()
{
    void some_function();
    return std::thread(some_function);
}
std::thread g()
{
    void some_other_function(int);
    std::thread t(some_other_function, 42);
    return t;
}
```

也可以作为参数传入：

```c++
void f(std::thread t);
void g()
{
    void some_function();
    f(std::thread(some_function));
    std::thread t(some_function);
    f(std::move(t));
}
```

:three:`std::thread `对象的容器，如果这个容器是==移动敏感的==（比如，`std::vector<> `)，那么**移动操作**同样适用于这些容器。

```c++
void do_work(unsigned id);
void f()
{
    std::vector<std::thread> threads;
    for(unsigned i=0; i < 20; ++i)
    {
    	threads.push_back(std::thread(do_work, i)); // 产生线程
    }
    std::for_each(threads.begin(),threads.end(),
    std::mem_fn(&std::thread::join)); // 对每个线程调用join()
}

```



## 1.4 运行时决定线程数量

:one:`std::thread::hardware_concurrency() `在新版C++标准库中是一个很有用的函数。这个函数将返回能**同时并发**在一个程序中的**线程数量**。例如，多核系统中，返回值可以是**CPU核芯的数量**。返回值仅仅是一个提示，当系统信息无法获取时，函数会返回`0`。

 :two:一个很好的例子——**并行累加器**，分析见书 P27

```c++
template<typename Iterator, typename T>
struct accumulate_block
{
    void operator()(Iterator first, Iterator last, T& result)
    {
    	result = std::accumulate(first, last, result);
    }
};

template<typename Iterator,typename T>
T parallel_accumulate(Iterator first,Iterator last,T init)
{
    unsigned long const length = std::distance(first,last);
    if(!length) // 1
    	return init;
    unsigned long const min_per_thread = 25;
    unsigned long const max_threads = (length+min_per_thread-1)/min_per_thread; // 2
    unsigned long const hardware_threads = std::thread::hardware_concurrency();
    unsigned long const num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads);
    unsigned long const block_size = length/num_threads; // 4
    std::vector<T> results(num_threads);
    std::vector<std::thread> threads(num_threads-1); // 5
    Iterator block_start = first;
    for(unsigned long i=0; i < (num_threads-1); ++i)
    {
        Iterator block_end = block_start;
        std::advance(block_end,block_size); // 6
        threads[i] = std::thread( // 7
        accumulate_block<Iterator,T>(),
        block_start,block_end,std::ref(results[i]));
        block_start = block_end; // 8
    }
    accumulate_block<Iterator,T>()(block_start, last, results[num_threads-1]); // 9
    std::for_each(threads.begin(), threads.end(), std::mem_fn(&std::thread::join)); // 10
    return std::accumulate(results.begin(), results.end(), init); // 11
}
```



## 1.5 标识线程

:one:线程标识符的类型是 `std::thread::id `，可以通过两种方式进行检索。

- 第一种，可以通过调用 **std::thread 对象**的成员函数 `get_id() `来直接获取。如果 `std::thread` 对象没有与任何**线程**相关联，` get_id() `将返回一个默认构造的`std::thread::type `值，表示“**没有线程**”。
- 第二种，当前线程中调用 `std::this_thread::get_id()`

这个标识符可以自由的复制和比较。可以在**关系容器**中作为**主键**使用。



# 2. 在线程间共享数据

## 2.1 线程间共享数据的问题

:one:线程间**潜在问题**就是**修改共享数据**，致使**不变量遭到破坏**。==条件竞争==(race condition)。

并发中**竞争条件的形成**，取决于一个以上线程的**相对执行顺序**，每个线程都抢着完成自己的任务。大多数情况下，即使改变执行顺序，也是良性竞争，其结果可以接受。

当**不变量遭到破坏**时，才会产生**条件竞争**，比如双向链表的例子。C++标准中定义了==数据竞争==这个术语，**一种特殊的条件竞争**：并发的去修改一个**独立对象**，**数据竞争是未定义行为的起因**。

:two:最简单的办法就是**对数据结构采用某种保护机制**， 确保只有进行修改的线程才能看到**不变量被破坏时的中间状态**。

另一个选择是对数据结构和不变量的设计进行修改，修改完的结构必须能**完成一系列不可分割的变化**，也就是保证每个不变量保持稳定的状态，这就是所谓的==无锁编程==。

另一种处理条件竞争的方式是，使用==事务==的方式去处理**数据结构的更新**。

C++**保护共享数据结构**的最基本的方式是==互斥元==。



## 2.2 使用互斥量保护共享数据

:one:C++通过实例化`std::mutex`创建**互斥量**，调用`lock`进行上锁，`unlock()`进行解锁。

不推荐实践中直接去调用成员函数，因为要记住在**函数出口处**调用`unlock`，还有考虑**异常**等情况。标准库提供了一个`RAII`语法的模板类`std::lack_guard`，其会在**构造**的时候提供**已锁的互斥量**，在**析构**时进行**解锁**。

> 头文件<mutex>

```c++
#include <list>
#include <mutex>
#include <algorithm>
std::list<int> some_list; // 1
std::mutex some_mutex; // 2
void add_to_list(int new_value)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 3
    some_list.push_back(new_value);
}
bool list_contains(int value_to_find)
{
    std::lock_guard<std::mutex> guard(some_mutex); // 4
    return std::find(some_list.begin(), some_list.end(), value_to_find) != some_list.end();
}
```

虽然某些情况下，使用**全局变量**没问题，但在大多数情况下，**互斥量**通常会与**保护的数据**放在同一个类中，而不是定义成全局变量。这是**面向对象设计的准则**：将其放在一个类中，就可让他们联系在一起，也可对**类的功能**进行封装，并进行数据保护。

> 当其中一个成员函数返回的是**保护数据的指针或引用**时，会破坏对数据的保护。对接口的设计要谨慎，要确保互斥量能锁住**任何对保护数据的访问**，并且不留后门

## 2.3 死锁：问题和解决方案

:one:避免死锁的一般建议，就是让**两个互斥量总以相同的顺序上锁**。某些情况下是可以这样用，因为不同的互斥量用于不同的地方。

不过，事情没那么简单，比如：当有**多个互斥量保护同一个类的独立实例**时，一个操作对**同一个类的两个不同实例**进行**数据的交换操作**，为了保证数据交换操作的正确性，就要避免数据被并发修改，并确保**每个实例上的互斥量**都能锁住自己要保护的区域。在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了。

:one:`std::lock`可以解决这一问题，这个函数可以同时锁定**两个或更多的互斥元**，并且没有副作用（死锁风险）。

```c++
// 这里的std::lock()需要包含<mutex>头文件
class some_big_object;
void swap(some_big_object& lhs, some_big_object& rhs);

class X
{
private:
    some_big_object some_detail;
    std::mutex m;
    
public:
    X(some_big_object const& sd) : some_detail(sd) {}
    
    friend void swap(X& lhs, X& rhs)
    {
        if(&lhs==&rhs)
        	return;
        std::lock(lhs.m, rhs.m); // 1
        std::lock_guard<std::mutex> lock_a(lhs.m, std::adopt_lock); // 2
        std::lock_guard<std::mutex> lock_b(rhs.m, std::adopt_lock); // 3
        swap(lhs.some_detail, rhs.some_detail);
    }
};
```

提供 `std::adopt_lock` 参数除了表示` std::lock_guard `对象已经上锁外，还表示要使用**现成的锁**（`std::lock`产生的），而非创建新的锁。

:three:当` std::lock` 成功的获取一个互斥量上的锁，并且当其尝试从另一个互斥量上再获取锁时，就会有异常抛出，**第一个锁也会随着异常的产生而自动释放**，所 以 **std::lock 要么将两个锁都锁住，要不一个都不锁**。

虽然 `std::lock `可以在同时获取两个以上的锁时避免死锁，但它没办法处理**分别获得的情况**。这时，不得不依赖于开发者的经验。



## 2.4 避免死锁的进一步指南

死锁的普遍性：仅需要2个 `std::thread` 对象调用对方的`join()`，两个线程就能产生死锁。**解决死锁的统一思路**为：如果有人等你，那就不要等他，==舔狗只能有一个==。

:one:**避免嵌套锁**。如果已经持有锁，就别再获取锁。因为每个线程只持有一个锁，就不会产生死锁。当你需要获取多个锁，使用一个 `std::lock `来做这件事，避免产生死锁。

:two:**在持有锁时，避免调用用户提供的代码**。因为代码是用户提供的，你没有办法确定用户要做什么；用户程序可能做任何事情，包括获取锁（违反上一条）。

:three:**以固定的顺序获取锁​**。要求你获取两个以上的锁，并且不能使用 `std::lock` 操作来获取它们；那么最好在每个线程上，用**固定的顺序**获取它们。

使用锁的层次结构：

```c++
class hierarchical_mutex
{
    std::mutex internal_mutex;
    unsigned long const hierarchy_value;
    unsigned long previous_hierarchy_value;
    static thread_local unsigned long this_thread_hierarchy_value; // 1
    
    void check_for_hierarchy_violation()
    {
        if(this_thread_hierarchy_value <= hierarchy_value) // 2
        {
        	throw std::logic_error(“mutex hierarchy violated”);
        }
    }
    
    void update_hierarchy_value()
    {
        previous_hierarchy_value = this_thread_hierarchy_value; // 3
        this_thread_hierarchy_value = hierarchy_value;
    }
    
public:
    
    explicit hierarchical_mutex(unsigned long value): hierarchy_value(value), previous_hierarchy_value(0) {}
    
    void lock()
    {
        check_for_hierarchy_violation();
        internal_mutex.lock(); // 4
        update_hierarchy_value(); // 5
    }
    
    void unlock()
    {
        this_thread_hierarchy_value = previous_hierarchy_value; // 6
        internal_mutex.unlock();
    }
    
    bool try_lock()
    {
        check_for_hierarchy_violation();
        if(!internal_mutex.try_lock()) // 7
        	return false;
        update_hierarchy_value();
        return true;
    }
};

thread_local unsigned long hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX);
```

这里重点是使用了`thread_local`的值来代表当前线程的层级值： `this_thread_hierarchy_value`①。它被初始化为最大值，所以最初所有线程都能被锁住。**因为其声明中有thread_local，所以每个线程都有其拷贝副本**，这样线程中变量状态完全独立， 当从另一个线程进行读取时，变量的状态也完全独立。

所以，第一次线程锁住一个`hierarchical_mutex`时，`this_thread_hierarchy_value`的值是 `ULONG_MAX`。一旦成功锁住，更新层级值。



## 2.5 使用`std::unique_lock`灵活锁定

:one:`std::unqiue_lock`使用更为自由的不变量，这样 `std::unique_lock `实例不会总与**互斥量**相关，使用起来要比 `std:lock_guard` 更加灵活。首先，可将 `std::adopt_lock` 作为第二个参数传入构造函数；也可以将 `std::defer_lock` 作为第二个参数传递进去，表明**互斥量应保持解锁状态**。

```c++
class some_big_object;
void swap(some_big_object& lhs,some_big_object& rhs);
class X
{
private:
    
    some_big_object some_detail;
    std::mutex m;
    
public:
    
    X(some_big_object const& sd):some_detail(sd){}
    
    friend void swap(X& lhs, X& rhs)
    {
        if(&lhs==&rhs)
        	return;
        std::unique_lock<std::mutex> lock_a(lhs.m, std::defer_lock); // 1
        std::unique_lock<std::mutex> lock_b(rhs.m, std::defer_lock); // 1 std::def_lock 留下未上锁的互斥量
        std::lock(lock_a,lock_b); // 2 互斥量在这里上锁
        swap(lhs.some_detail,rhs.some_detail);
    }
};
```

:two:因为 `std::unique_lock `支持`lock()`，`try_lock()`和`unlock()`成员函数，所以能将`std::unique_lock `对象传递到` std::lock() `。这些同名的成员函数在低层做着实际的工作，并且仅更新 `std::unique_lock` 实例中的==标志==，来确定该实例是否拥有特定的互斥量，**这个标志是为了确保`unlock()`在析构函数中被正确调用**。如果实例拥有互斥量，那么析构函数必须调用unlock()；但当实例中没有互斥量时，析构函数就不能去调用unlock()。这个标志可以通过`owns_lock()`成员变量进行查询。

:three:`std::unique_lock `对象的体积通常要比 `std::lock_guard `对象大，当 `std::lock_guard` 已经能够满足需求，那么还是建议使用它。当需要**更加灵活的锁**时，最好选择 `std::unique_lock` ，因为它更适合于你的任务。



## 2.6 在作用域之间转移锁的所有权

:one:`std::unique_lock`实例没有**与其相关的互斥量**，一个互斥量的所有权可以通过移动操作，在不同的实例中进行传递。`std::unique_lock `是**可移动，但不可复制**的类型。

```c++
std::unique_lock<std::mutex> get_lock()
{
    extern std::mutex some_mutex;
    std::unique_lock<std::mutex> lk(some_mutex);
    prepare_data();
    return lk; // 1
}
void process_data()
{
    std::unique_lock<std::mutex> lk(get_lock()); // 2
    do_something();
}

```

:two:`std::unique_lock `，在调用`unlock()`时，代码不需要再访问共享数据； 而后当再次需要对共享数据进行访问时，就可以再调用`lock()`了。

```c++
void get_and_process_data()
{
    std::unique_lock<std::mutex> my_lock(the_mutex);
    some_class data_to_process = get_next_data_chunk();
    my_lock.unlock(); // 1 不要让锁住的互斥量越过process()函数的调用
    result_type result = process(data_to_process);
    my_lock.lock(); // 2 为了写入数据，对互斥量再次上锁
    write_result(data_to_process, result);
}
```

